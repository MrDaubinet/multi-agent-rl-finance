{"custom_metrics": {"net_worth_mean": 7.528669680270586, "net_worth_min": 5.7004657623148365, "net_worth_max": 9.324075637244109}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": 7.8228888511657715, "policy_loss": -0.026586735621094704, "vf_loss": 7.844820976257324, "vf_explained_var": -0.007512660231441259, "kl": 0.023270640522241592, "entropy": 0.6704647541046143, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 5388, "num_env_steps_trained": 5388, "num_agent_steps_sampled": 5388, "num_agent_steps_trained": 5388}, "sampler_results": {"episode_reward_max": 4.2802205419726675, "episode_reward_min": -50.56747450958373, "episode_reward_mean": -18.954592583563137, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 7.528669680270586, "net_worth_min": 5.7004657623148365, "net_worth_max": 9.324075637244109}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.042508635393589816, "mean_inference_ms": 2.7568192616414593, "mean_action_processing_ms": 0.028733020366476264, "mean_env_wait_ms": 0.31844661391453505, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 4.2802205419726675, "episode_reward_min": -50.56747450958373, "episode_reward_mean": -18.954592583563137, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.042508635393589816, "mean_inference_ms": 2.7568192616414593, "mean_action_processing_ms": 0.028733020366476264, "mean_env_wait_ms": 0.31844661391453505, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 5388, "num_agent_steps_trained": 5388, "num_env_steps_sampled": 5388, "num_env_steps_trained": 5388, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 5388, "agent_timesteps_total": 5388, "timers": {"training_iteration_time_ms": 26811.682, "load_time_ms": 0.085, "load_throughput": 63302268.773, "learn_time_ms": 9810.533, "learn_throughput": 549.206, "update_time_ms": 15.554}, "counters": {"num_env_steps_sampled": 5388, "num_env_steps_trained": 5388, "num_agent_steps_sampled": 5388, "num_agent_steps_trained": 5388}, "done": false, "episodes_total": 12, "training_iteration": 1, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-07-38", "timestamp": 1656241658, "time_this_iter_s": 26.81322193145752, "time_total_s": 26.81322193145752, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 26.81322193145752, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 42.22564102564102, "ram_util_percent": 79.70256410256411}}
{"custom_metrics": {"net_worth_mean": 13.316395724076186, "net_worth_min": 5.7004657623148365, "net_worth_max": 28.00292185}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.924459457397461, "policy_loss": -0.017519300803542137, "vf_loss": 9.938251495361328, "vf_explained_var": -0.00500777643173933, "kl": 0.012419108301401138, "entropy": 0.6160567402839661, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 10776, "num_env_steps_trained": 10776, "num_agent_steps_sampled": 10776, "num_agent_steps_trained": 10776}, "sampler_results": {"episode_reward_max": 153.69997888867593, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 51.493750369193286, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 13.316395724076186, "net_worth_min": 5.7004657623148365, "net_worth_max": 28.00292185}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04376475823657783, "mean_inference_ms": 2.816699898616441, "mean_action_processing_ms": 0.030610445699255844, "mean_env_wait_ms": 0.32235191961358656, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 153.69997888867593, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 51.493750369193286, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04376475823657783, "mean_inference_ms": 2.816699898616441, "mean_action_processing_ms": 0.030610445699255844, "mean_env_wait_ms": 0.32235191961358656, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 10776, "num_agent_steps_trained": 10776, "num_env_steps_sampled": 10776, "num_env_steps_trained": 10776, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 10776, "agent_timesteps_total": 10776, "timers": {"training_iteration_time_ms": 27577.149, "load_time_ms": 0.7, "load_throughput": 7702423.297, "learn_time_ms": 9862.779, "learn_throughput": 546.296, "update_time_ms": 14.7}, "counters": {"num_env_steps_sampled": 10776, "num_env_steps_trained": 10776, "num_agent_steps_sampled": 10776, "num_agent_steps_trained": 10776}, "done": false, "episodes_total": 24, "training_iteration": 2, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-08-07", "timestamp": 1656241687, "time_this_iter_s": 28.343992948532104, "time_total_s": 55.157214879989624, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 55.157214879989624, "timesteps_since_restore": 0, "iterations_since_restore": 2, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 39.1, "ram_util_percent": 80.235}}
{"custom_metrics": {"net_worth_mean": 20.173382901861213, "net_worth_min": 5.7004657623148365, "net_worth_max": 53.068374}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.919434547424316, "policy_loss": -0.013385591097176075, "vf_loss": 9.930143356323242, "vf_explained_var": 0.016234224662184715, "kl": 0.008922216482460499, "entropy": 0.582276463508606, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 16164, "num_env_steps_trained": 16164, "num_agent_steps_sampled": 16164, "num_agent_steps_trained": 16164}, "sampler_results": {"episode_reward_max": 242.67855463361875, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 96.00874640969616, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 20.173382901861213, "net_worth_min": 5.7004657623148365, "net_worth_max": 53.068374}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04393352136013966, "mean_inference_ms": 2.830876496711223, "mean_action_processing_ms": 0.03098417814764902, "mean_env_wait_ms": 0.3188794541668495, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 242.67855463361875, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 96.00874640969616, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04393352136013966, "mean_inference_ms": 2.830876496711223, "mean_action_processing_ms": 0.03098417814764902, "mean_env_wait_ms": 0.3188794541668495, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 16164, "num_agent_steps_trained": 16164, "num_env_steps_sampled": 16164, "num_env_steps_trained": 16164, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 16164, "agent_timesteps_total": 16164, "timers": {"training_iteration_time_ms": 27225.541, "load_time_ms": 0.535, "load_throughput": 10064835.192, "learn_time_ms": 9694.29, "learn_throughput": 555.791, "update_time_ms": 13.615}, "counters": {"num_env_steps_sampled": 16164, "num_env_steps_trained": 16164, "num_agent_steps_sampled": 16164, "num_agent_steps_trained": 16164}, "done": false, "episodes_total": 36, "training_iteration": 3, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-08-33", "timestamp": 1656241713, "time_this_iter_s": 26.523582935333252, "time_total_s": 81.68079781532288, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 81.68079781532288, "timesteps_since_restore": 0, "iterations_since_restore": 3, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 32.47105263157895, "ram_util_percent": 80.16578947368421}}
{"custom_metrics": {"net_worth_mean": 27.327342911122354, "net_worth_min": 5.7004657623148365, "net_worth_max": 65.24851433879243}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.89295768737793, "policy_loss": -0.009661205112934113, "vf_loss": 9.90005874633789, "vf_explained_var": -0.0006230214494280517, "kl": 0.008534908294677734, "entropy": 0.5461280345916748, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 21552, "num_env_steps_trained": 21552, "num_agent_steps_sampled": 21552, "num_agent_steps_trained": 21552}, "sampler_results": {"episode_reward_max": 257.70052995157596, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 129.79546232015187, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 27.327342911122354, "net_worth_min": 5.7004657623148365, "net_worth_max": 65.24851433879243}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04386715643114051, "mean_inference_ms": 2.83028861738255, "mean_action_processing_ms": 0.03091288695590844, "mean_env_wait_ms": 0.3156347140383802, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 257.70052995157596, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 129.79546232015187, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04386715643114051, "mean_inference_ms": 2.83028861738255, "mean_action_processing_ms": 0.03091288695590844, "mean_env_wait_ms": 0.3156347140383802, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 21552, "num_agent_steps_trained": 21552, "num_env_steps_sampled": 21552, "num_env_steps_trained": 21552, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 21552, "agent_timesteps_total": 21552, "timers": {"training_iteration_time_ms": 26872.579, "load_time_ms": 0.68, "load_throughput": 7920410.042, "learn_time_ms": 9549.469, "learn_throughput": 564.22, "update_time_ms": 13.613}, "counters": {"num_env_steps_sampled": 21552, "num_env_steps_trained": 21552, "num_agent_steps_sampled": 21552, "num_agent_steps_trained": 21552}, "done": false, "episodes_total": 48, "training_iteration": 4, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-08-59", "timestamp": 1656241739, "time_this_iter_s": 25.81511664390564, "time_total_s": 107.49591445922852, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 107.49591445922852, "timesteps_since_restore": 0, "iterations_since_restore": 4, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 42.23513513513514, "ram_util_percent": 80.21891891891893}}
{"evaluation": {"episode_reward_max": 440.3446947672844, "episode_reward_min": 440.3446947672844, "episode_reward_mean": 440.3446947672844, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 799.45612396, "net_worth_min": 799.45612396, "net_worth_max": 799.45612396}, "hist_stats": {"episode_reward": [440.3446947672844], "episode_lengths": [449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.06616433461507162, "mean_inference_ms": 3.424888186984592, "mean_action_processing_ms": 0.03562503390842014, "mean_env_wait_ms": 0.2620834774441189, "mean_env_render_ms": 26.064083841111927}, "off_policy_estimator": {}, "timesteps_this_iter": 0}, "custom_metrics": {"net_worth_mean": 34.52755119273021, "net_worth_min": 5.7004657623148365, "net_worth_max": 83.24594406}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.913368225097656, "policy_loss": -0.013173283077776432, "vf_loss": 9.92365550994873, "vf_explained_var": 0.0009224496316164732, "kl": 0.009620245546102524, "entropy": 0.5129808187484741, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 26940, "num_env_steps_trained": 26940, "num_agent_steps_sampled": 26940, "num_agent_steps_trained": 26940}, "sampler_results": {"episode_reward_max": 269.1402039633972, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 153.74043078126633, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 34.52755119273021, "net_worth_min": 5.7004657623148365, "net_worth_max": 83.24594406}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.043746732114803774, "mean_inference_ms": 2.825886259774628, "mean_action_processing_ms": 0.03073482980316364, "mean_env_wait_ms": 0.31258956640723506, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 269.1402039633972, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 153.74043078126633, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.043746732114803774, "mean_inference_ms": 2.825886259774628, "mean_action_processing_ms": 0.03073482980316364, "mean_env_wait_ms": 0.31258956640723506, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 26940, "num_agent_steps_trained": 26940, "num_env_steps_sampled": 26940, "num_env_steps_trained": 26940, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 26940, "agent_timesteps_total": 26940, "timers": {"training_iteration_time_ms": 26645.28, "load_time_ms": 0.593, "load_throughput": 9085354.166, "learn_time_ms": 9468.098, "learn_throughput": 569.069, "update_time_ms": 13.313}, "counters": {"num_env_steps_sampled": 26940, "num_env_steps_trained": 26940, "num_agent_steps_sampled": 26940, "num_agent_steps_trained": 26940}, "done": false, "episodes_total": 60, "training_iteration": 5, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-09-38", "timestamp": 1656241778, "time_this_iter_s": 39.18747591972351, "time_total_s": 146.68339037895203, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 146.68339037895203, "timesteps_since_restore": 0, "iterations_since_restore": 5, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 39.25714285714286, "ram_util_percent": 80.05357142857143}}
{"custom_metrics": {"net_worth_mean": 42.72363638977518, "net_worth_min": 5.7004657623148365, "net_worth_max": 101.19361877}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.921527862548828, "policy_loss": -0.007945995777845383, "vf_loss": 9.927550315856934, "vf_explained_var": 0.002131336834281683, "kl": 0.006410764530301094, "entropy": 0.47746896743774414, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 32328, "num_env_steps_trained": 32328, "num_agent_steps_sampled": 32328, "num_agent_steps_trained": 32328}, "sampler_results": {"episode_reward_max": 297.3189874493223, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 174.38718972296587, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 42.72363638977518, "net_worth_min": 5.7004657623148365, "net_worth_max": 101.19361877}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04362289595366428, "mean_inference_ms": 2.8208527899417777, "mean_action_processing_ms": 0.030556557185458293, "mean_env_wait_ms": 0.3097851663199007, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 297.3189874493223, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 174.38718972296587, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04362289595366428, "mean_inference_ms": 2.8208527899417777, "mean_action_processing_ms": 0.030556557185458293, "mean_env_wait_ms": 0.3097851663199007, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 32328, "num_agent_steps_trained": 32328, "num_env_steps_sampled": 32328, "num_env_steps_trained": 32328, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 32328, "agent_timesteps_total": 32328, "timers": {"training_iteration_time_ms": 26506.925, "load_time_ms": 0.723, "load_throughput": 7448553.049, "learn_time_ms": 9426.757, "learn_throughput": 571.565, "update_time_ms": 13.062}, "counters": {"num_env_steps_sampled": 32328, "num_env_steps_trained": 32328, "num_agent_steps_sampled": 32328, "num_agent_steps_trained": 32328}, "done": false, "episodes_total": 72, "training_iteration": 6, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-10-04", "timestamp": 1656241804, "time_this_iter_s": 25.816720962524414, "time_total_s": 172.50011134147644, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 172.50011134147644, "timesteps_since_restore": 0, "iterations_since_restore": 6, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 41.82972972972973, "ram_util_percent": 80.40810810810808}}
{"custom_metrics": {"net_worth_mean": 52.09153716413429, "net_worth_min": 5.7004657623148365, "net_worth_max": 207.03634164}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.907392501831055, "policy_loss": -0.008917136117815971, "vf_loss": 9.913985252380371, "vf_explained_var": -0.004251335747539997, "kl": 0.007747109513729811, "entropy": 0.4573335647583008, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 37716, "num_env_steps_trained": 37716, "num_agent_steps_sampled": 37716, "num_agent_steps_trained": 37716}, "sampler_results": {"episode_reward_max": 351.47679854760213, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 192.02994094194435, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 52.09153716413429, "net_worth_min": 5.7004657623148365, "net_worth_max": 207.03634164}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04351034859312263, "mean_inference_ms": 2.8160042321248007, "mean_action_processing_ms": 0.030401869683611478, "mean_env_wait_ms": 0.3068356033575916, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 351.47679854760213, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 192.02994094194435, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04351034859312263, "mean_inference_ms": 2.8160042321248007, "mean_action_processing_ms": 0.030401869683611478, "mean_env_wait_ms": 0.3068356033575916, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 37716, "num_agent_steps_trained": 37716, "num_env_steps_sampled": 37716, "num_env_steps_trained": 37716, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 37716, "agent_timesteps_total": 37716, "timers": {"training_iteration_time_ms": 26383.002, "load_time_ms": 0.65, "load_throughput": 8292743.22, "learn_time_ms": 9388.441, "learn_throughput": 573.897, "update_time_ms": 12.928}, "counters": {"num_env_steps_sampled": 37716, "num_env_steps_trained": 37716, "num_agent_steps_sampled": 37716, "num_agent_steps_trained": 37716}, "done": false, "episodes_total": 84, "training_iteration": 7, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-10-30", "timestamp": 1656241830, "time_this_iter_s": 25.64100193977356, "time_total_s": 198.14111328125, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 198.14111328125, "timesteps_since_restore": 0, "iterations_since_restore": 7, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 41.851351351351354, "ram_util_percent": 80.42972972972974}}
{"custom_metrics": {"net_worth_mean": 60.51463097718574, "net_worth_min": 5.7004657623148365, "net_worth_max": 207.03634164}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.904332160949707, "policy_loss": -0.004743972327560186, "vf_loss": 9.906389236450195, "vf_explained_var": -0.009970192797482014, "kl": 0.008957218378782272, "entropy": 0.4481315612792969, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 43104, "num_env_steps_trained": 43104, "num_agent_steps_sampled": 43104, "num_agent_steps_trained": 43104}, "sampler_results": {"episode_reward_max": 351.47679854760213, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 206.552044596899, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 60.51463097718574, "net_worth_min": 5.7004657623148365, "net_worth_max": 207.03634164}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04340216786272047, "mean_inference_ms": 2.811455146096455, "mean_action_processing_ms": 0.03025837360191699, "mean_env_wait_ms": 0.3041989162287209, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 351.47679854760213, "episode_reward_min": -50.56747450958373, "episode_reward_mean": 206.552044596899, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-39.175093251189935, -11.449451697036338, -49.48846912933395, -12.735111950921109, -12.938573988778657, -50.56747450958373, 0.5636417842655561, -11.370635752216316, -18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04340216786272047, "mean_inference_ms": 2.811455146096455, "mean_action_processing_ms": 0.03025837360191699, "mean_env_wait_ms": 0.3041989162287209, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 43104, "num_agent_steps_trained": 43104, "num_env_steps_sampled": 43104, "num_env_steps_trained": 43104, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 43104, "agent_timesteps_total": 43104, "timers": {"training_iteration_time_ms": 26308.183, "load_time_ms": 0.594, "load_throughput": 9068583.448, "learn_time_ms": 9373.998, "learn_throughput": 574.781, "update_time_ms": 12.85}, "counters": {"num_env_steps_sampled": 43104, "num_env_steps_trained": 43104, "num_agent_steps_sampled": 43104, "num_agent_steps_trained": 43104}, "done": false, "episodes_total": 96, "training_iteration": 8, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-10-56", "timestamp": 1656241856, "time_this_iter_s": 25.786095142364502, "time_total_s": 223.9272084236145, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 223.9272084236145, "timesteps_since_restore": 0, "iterations_since_restore": 8, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 42.44444444444444, "ram_util_percent": 80.29722222222223}}
{"custom_metrics": {"net_worth_mean": 72.89046913827609, "net_worth_min": 5.7004657623148365, "net_worth_max": 207.03634164}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.916030883789062, "policy_loss": -0.00852109957486391, "vf_loss": 9.922170639038086, "vf_explained_var": -0.0040855747647583485, "kl": 0.007937821559607983, "entropy": 0.4310380220413208, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 48492, "num_env_steps_trained": 48492, "num_agent_steps_sampled": 48492, "num_agent_steps_trained": 48492}, "sampler_results": {"episode_reward_max": 351.47679854760213, "episode_reward_min": -27.630778959548223, "episode_reward_mean": 237.86511761306238, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 72.89046913827609, "net_worth_min": 5.7004657623148365, "net_worth_max": 207.03634164}, "hist_stats": {"episode_reward": [-18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844, 316.7885911173271, 317.51310453547296, 316.8857048198008, 329.5736585482715, 338.2544442744039, 313.01073581291064, 307.25466796098726, 325.4464209500445, 297.00010881344474, 296.4460067245177, 298.6112887117148, 313.56957924024255], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04335920320437739, "mean_inference_ms": 2.8092551376324466, "mean_action_processing_ms": 0.030211631593210286, "mean_env_wait_ms": 0.29952410955369113, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 351.47679854760213, "episode_reward_min": -27.630778959548223, "episode_reward_mean": 237.86511761306238, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-18.541009275953144, -27.630778959548223, 1.5976251855655619, 4.2802205419726675, 122.9397452380914, 99.56781509761632, 141.131797294376, 111.68946715298026, 68.54919083021258, 153.69997888867593, 134.55262139100378, 109.79964420637306, 141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844, 316.7885911173271, 317.51310453547296, 316.8857048198008, 329.5736585482715, 338.2544442744039, 313.01073581291064, 307.25466796098726, 325.4464209500445, 297.00010881344474, 296.4460067245177, 298.6112887117148, 313.56957924024255], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04335920320437739, "mean_inference_ms": 2.8092551376324466, "mean_action_processing_ms": 0.030211631593210286, "mean_env_wait_ms": 0.29952410955369113, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 48492, "num_agent_steps_trained": 48492, "num_env_steps_sampled": 48492, "num_env_steps_trained": 48492, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 48492, "agent_timesteps_total": 48492, "timers": {"training_iteration_time_ms": 26230.95, "load_time_ms": 0.552, "load_throughput": 9762885.305, "learn_time_ms": 9354.604, "learn_throughput": 575.973, "update_time_ms": 12.992}, "counters": {"num_env_steps_sampled": 48492, "num_env_steps_trained": 48492, "num_agent_steps_sampled": 48492, "num_agent_steps_trained": 48492}, "done": false, "episodes_total": 108, "training_iteration": 9, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-11-22", "timestamp": 1656241882, "time_this_iter_s": 25.614699125289917, "time_total_s": 249.54190754890442, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 249.54190754890442, "timesteps_since_restore": 0, "iterations_since_restore": 9, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 42.22702702702702, "ram_util_percent": 80.65135135135134}}
{"evaluation": {"episode_reward_max": 448.48435829176117, "episode_reward_min": 448.48435829176117, "episode_reward_mean": 448.48435829176117, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 862.47269361, "net_worth_min": 862.47269361, "net_worth_max": 862.47269361}, "hist_stats": {"episode_reward": [448.48435829176117], "episode_lengths": [449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.06605891948016784, "mean_inference_ms": 3.4584190211651453, "mean_action_processing_ms": 0.03708138216589396, "mean_env_wait_ms": 0.2620254660872649, "mean_env_render_ms": 26.015164456988067}, "off_policy_estimator": {}, "timesteps_this_iter": 0}, "custom_metrics": {"net_worth_mean": 88.31229426742138, "net_worth_min": 15.54702385, "net_worth_max": 207.03634164}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.923896789550781, "policy_loss": -0.0042257229797542095, "vf_loss": 9.926581382751465, "vf_explained_var": -0.0061505455523729324, "kl": 0.005137085448950529, "entropy": 0.4141927659511566, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 53880, "num_env_steps_trained": 53880, "num_agent_steps_sampled": 53880, "num_agent_steps_trained": 53880}, "sampler_results": {"episode_reward_max": 353.86445977899155, "episode_reward_min": 103.09565416917539, "episode_reward_mean": 268.10027368265963, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 88.31229426742138, "net_worth_min": 15.54702385, "net_worth_max": 207.03634164}, "hist_stats": {"episode_reward": [141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844, 316.7885911173271, 317.51310453547296, 316.8857048198008, 329.5736585482715, 338.2544442744039, 313.01073581291064, 307.25466796098726, 325.4464209500445, 297.00010881344474, 296.4460067245177, 298.6112887117148, 313.56957924024255, 332.99931847581433, 297.22795498010544, 353.24964115069724, 307.57907123240045, 306.8763598234849, 353.86445977899155, 317.25912402209553, 321.1876698460218, 327.82495181898616, 345.71252783621026, 333.9178916003592, 327.4529539859258], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.043162322385298484, "mean_inference_ms": 2.8014808749020013, "mean_action_processing_ms": 0.029951732903384373, "mean_env_wait_ms": 0.2945987660006192, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 353.86445977899155, "episode_reward_min": 103.09565416917539, "episode_reward_mean": 268.10027368265963, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [141.17047607293742, 131.35054822165435, 103.09565416917539, 145.75818130029992, 183.02818958221096, 170.99526633987708, 242.67855463361875, 161.80716695939307, 154.32813573433603, 207.79946601319173, 178.45070142085856, 188.9188647658357, 136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844, 316.7885911173271, 317.51310453547296, 316.8857048198008, 329.5736585482715, 338.2544442744039, 313.01073581291064, 307.25466796098726, 325.4464209500445, 297.00010881344474, 296.4460067245177, 298.6112887117148, 313.56957924024255, 332.99931847581433, 297.22795498010544, 353.24964115069724, 307.57907123240045, 306.8763598234849, 353.86445977899155, 317.25912402209553, 321.1876698460218, 327.82495181898616, 345.71252783621026, 333.9178916003592, 327.4529539859258], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.043162322385298484, "mean_inference_ms": 2.8014808749020013, "mean_action_processing_ms": 0.029951732903384373, "mean_env_wait_ms": 0.2945987660006192, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 53880, "num_agent_steps_trained": 53880, "num_env_steps_sampled": 53880, "num_env_steps_trained": 53880, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 53880, "agent_timesteps_total": 53880, "timers": {"training_iteration_time_ms": 26245.963, "load_time_ms": 0.619, "load_throughput": 8702599.335, "learn_time_ms": 9364.032, "learn_throughput": 575.393, "update_time_ms": 13.006}, "counters": {"num_env_steps_sampled": 53880, "num_env_steps_trained": 53880, "num_agent_steps_sampled": 53880, "num_agent_steps_trained": 53880}, "done": false, "episodes_total": 120, "training_iteration": 10, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-12-02", "timestamp": 1656241922, "time_this_iter_s": 39.78018403053284, "time_total_s": 289.32209157943726, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 289.32209157943726, "timesteps_since_restore": 0, "iterations_since_restore": 10, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 32.49649122807018, "ram_util_percent": 81.25087719298246}}
{"custom_metrics": {"net_worth_mean": 103.0012393656981, "net_worth_min": 24.011691954409226, "net_worth_max": 207.03634164}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.92581558227539, "policy_loss": -0.00563192879781127, "vf_loss": 9.929617881774902, "vf_explained_var": -0.013975937850773335, "kl": 0.006094853859394789, "entropy": 0.4053517282009125, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 59268, "num_env_steps_trained": 59268, "num_agent_steps_sampled": 59268, "num_agent_steps_trained": 59268}, "sampler_results": {"episode_reward_max": 354.45939640674715, "episode_reward_min": 136.99540342849045, "episode_reward_mean": 287.5784867099149, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 103.0012393656981, "net_worth_min": 24.011691954409226, "net_worth_max": 207.03634164}, "hist_stats": {"episode_reward": [136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844, 316.7885911173271, 317.51310453547296, 316.8857048198008, 329.5736585482715, 338.2544442744039, 313.01073581291064, 307.25466796098726, 325.4464209500445, 297.00010881344474, 296.4460067245177, 298.6112887117148, 313.56957924024255, 332.99931847581433, 297.22795498010544, 353.24964115069724, 307.57907123240045, 306.8763598234849, 353.86445977899155, 317.25912402209553, 321.1876698460218, 327.82495181898616, 345.71252783621026, 333.9178916003592, 327.4529539859258, 351.0471416153722, 316.8711635397632, 342.94588565713343, 334.02057662916604, 282.7421706285222, 354.45939640674715, 349.20376518844876, 326.0063625302298, 299.6010915863644, 305.35846377595976, 342.8588954532579, 352.08759492794707], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04292493082570898, "mean_inference_ms": 2.7915238848824173, "mean_action_processing_ms": 0.02959919721715517, "mean_env_wait_ms": 0.2900828417844073, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 354.45939640674715, "episode_reward_min": 136.99540342849045, "episode_reward_mean": 287.5784867099149, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [136.99540342849045, 191.1313093480152, 215.5154177562783, 188.81638590631715, 231.9089246729467, 214.86040795866919, 257.70052995157596, 254.92785533980427, 238.3671601926694, 220.82023003402603, 203.80031471613304, 228.94423544226524, 204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844, 316.7885911173271, 317.51310453547296, 316.8857048198008, 329.5736585482715, 338.2544442744039, 313.01073581291064, 307.25466796098726, 325.4464209500445, 297.00010881344474, 296.4460067245177, 298.6112887117148, 313.56957924024255, 332.99931847581433, 297.22795498010544, 353.24964115069724, 307.57907123240045, 306.8763598234849, 353.86445977899155, 317.25912402209553, 321.1876698460218, 327.82495181898616, 345.71252783621026, 333.9178916003592, 327.4529539859258, 351.0471416153722, 316.8711635397632, 342.94588565713343, 334.02057662916604, 282.7421706285222, 354.45939640674715, 349.20376518844876, 326.0063625302298, 299.6010915863644, 305.35846377595976, 342.8588954532579, 352.08759492794707], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04292493082570898, "mean_inference_ms": 2.7915238848824173, "mean_action_processing_ms": 0.02959919721715517, "mean_env_wait_ms": 0.2900828417844073, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 59268, "num_agent_steps_trained": 59268, "num_env_steps_sampled": 59268, "num_env_steps_trained": 59268, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 59268, "agent_timesteps_total": 59268, "timers": {"training_iteration_time_ms": 26231.143, "load_time_ms": 0.631, "load_throughput": 8534331.553, "learn_time_ms": 9345.542, "learn_throughput": 576.532, "update_time_ms": 12.681}, "counters": {"num_env_steps_sampled": 59268, "num_env_steps_trained": 59268, "num_agent_steps_sampled": 59268, "num_agent_steps_trained": 59268}, "done": false, "episodes_total": 132, "training_iteration": 11, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-12-28", "timestamp": 1656241948, "time_this_iter_s": 26.665199041366577, "time_total_s": 315.98729062080383, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 315.98729062080383, "timesteps_since_restore": 0, "iterations_since_restore": 11, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 30.04736842105263, "ram_util_percent": 81.48947368421054}}
{"custom_metrics": {"net_worth_mean": 117.47427089278025, "net_worth_min": 33.30566654, "net_worth_max": 219.16954993}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.928874015808105, "policy_loss": -0.006103561259806156, "vf_loss": 9.932347297668457, "vf_explained_var": -0.010467063635587692, "kl": 0.008767083287239075, "entropy": 0.4007730782032013, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 64656, "num_env_steps_trained": 64656, "num_agent_steps_sampled": 64656, "num_agent_steps_trained": 64656}, "sampler_results": {"episode_reward_max": 367.3974562070364, "episode_reward_min": 204.7655404263327, "episode_reward_mean": 302.9363674719457, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 117.47427089278025, "net_worth_min": 33.30566654, "net_worth_max": 219.16954993}, "hist_stats": {"episode_reward": [204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844, 316.7885911173271, 317.51310453547296, 316.8857048198008, 329.5736585482715, 338.2544442744039, 313.01073581291064, 307.25466796098726, 325.4464209500445, 297.00010881344474, 296.4460067245177, 298.6112887117148, 313.56957924024255, 332.99931847581433, 297.22795498010544, 353.24964115069724, 307.57907123240045, 306.8763598234849, 353.86445977899155, 317.25912402209553, 321.1876698460218, 327.82495181898616, 345.71252783621026, 333.9178916003592, 327.4529539859258, 351.0471416153722, 316.8711635397632, 342.94588565713343, 334.02057662916604, 282.7421706285222, 354.45939640674715, 349.20376518844876, 326.0063625302298, 299.6010915863644, 305.35846377595976, 342.8588954532579, 352.08759492794707, 354.3759469587309, 324.6251361447712, 354.038418812101, 358.0596834391383, 341.6904903107278, 347.4227038905856, 334.2302519532311, 367.3974562070364, 341.8786603773999, 333.49825424911205, 336.79349682709005, 325.56575178034507], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04275386324857414, "mean_inference_ms": 2.784943350224442, "mean_action_processing_ms": 0.029348906635526775, "mean_env_wait_ms": 0.28597630109890654, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 367.3974562070364, "episode_reward_min": 204.7655404263327, "episode_reward_mean": 302.9363674719457, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [204.7655404263327, 251.0605317771576, 217.6960908501296, 249.01549925651935, 269.1402039633972, 261.3831064560254, 258.0244462594304, 255.8062500550494, 241.68477460376332, 257.70888911157317, 225.34475905583886, 241.63273190963636, 250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844, 316.7885911173271, 317.51310453547296, 316.8857048198008, 329.5736585482715, 338.2544442744039, 313.01073581291064, 307.25466796098726, 325.4464209500445, 297.00010881344474, 296.4460067245177, 298.6112887117148, 313.56957924024255, 332.99931847581433, 297.22795498010544, 353.24964115069724, 307.57907123240045, 306.8763598234849, 353.86445977899155, 317.25912402209553, 321.1876698460218, 327.82495181898616, 345.71252783621026, 333.9178916003592, 327.4529539859258, 351.0471416153722, 316.8711635397632, 342.94588565713343, 334.02057662916604, 282.7421706285222, 354.45939640674715, 349.20376518844876, 326.0063625302298, 299.6010915863644, 305.35846377595976, 342.8588954532579, 352.08759492794707, 354.3759469587309, 324.6251361447712, 354.038418812101, 358.0596834391383, 341.6904903107278, 347.4227038905856, 334.2302519532311, 367.3974562070364, 341.8786603773999, 333.49825424911205, 336.79349682709005, 325.56575178034507], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04275386324857414, "mean_inference_ms": 2.784943350224442, "mean_action_processing_ms": 0.029348906635526775, "mean_env_wait_ms": 0.28597630109890654, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 64656, "num_agent_steps_trained": 64656, "num_env_steps_sampled": 64656, "num_env_steps_trained": 64656, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 64656, "agent_timesteps_total": 64656, "timers": {"training_iteration_time_ms": 26036.535, "load_time_ms": 0.525, "load_throughput": 10268031.238, "learn_time_ms": 9313.206, "learn_throughput": 578.533, "update_time_ms": 12.529}, "counters": {"num_env_steps_sampled": 64656, "num_env_steps_trained": 64656, "num_agent_steps_sampled": 64656, "num_agent_steps_trained": 64656}, "done": false, "episodes_total": 144, "training_iteration": 12, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-12-55", "timestamp": 1656241975, "time_this_iter_s": 26.398218870162964, "time_total_s": 342.3855094909668, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 342.3855094909668, "timesteps_since_restore": 0, "iterations_since_restore": 12, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 30.05945945945946, "ram_util_percent": 81.36486486486487}}
{"custom_metrics": {"net_worth_mean": 131.47207294217006, "net_worth_min": 52.23022049, "net_worth_max": 236.18349603}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 4.999999873689376e-05, "total_loss": 9.927703857421875, "policy_loss": -0.004607238341122866, "vf_loss": 9.930310249328613, "vf_explained_var": -0.006405190099030733, "kl": 0.006667318753898144, "entropy": 0.3743889331817627, "entropy_coeff": 0.0, "model": {}}, "custom_metrics": {}, "num_agent_steps_trained": 128.0}}, "num_env_steps_sampled": 70044, "num_env_steps_trained": 70044, "num_agent_steps_sampled": 70044, "num_agent_steps_trained": 70044}, "sampler_results": {"episode_reward_max": 367.3974562070364, "episode_reward_min": 221.97187502035055, "episode_reward_mean": 314.5382313711571, "episode_len_mean": 449.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {"net_worth_mean": 131.47207294217006, "net_worth_min": 52.23022049, "net_worth_max": 236.18349603}, "hist_stats": {"episode_reward": [250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844, 316.7885911173271, 317.51310453547296, 316.8857048198008, 329.5736585482715, 338.2544442744039, 313.01073581291064, 307.25466796098726, 325.4464209500445, 297.00010881344474, 296.4460067245177, 298.6112887117148, 313.56957924024255, 332.99931847581433, 297.22795498010544, 353.24964115069724, 307.57907123240045, 306.8763598234849, 353.86445977899155, 317.25912402209553, 321.1876698460218, 327.82495181898616, 345.71252783621026, 333.9178916003592, 327.4529539859258, 351.0471416153722, 316.8711635397632, 342.94588565713343, 334.02057662916604, 282.7421706285222, 354.45939640674715, 349.20376518844876, 326.0063625302298, 299.6010915863644, 305.35846377595976, 342.8588954532579, 352.08759492794707, 354.3759469587309, 324.6251361447712, 354.038418812101, 358.0596834391383, 341.6904903107278, 347.4227038905856, 334.2302519532311, 367.3974562070364, 341.8786603773999, 333.49825424911205, 336.79349682709005, 325.56575178034507, 364.22508533567463, 329.9446439743964, 344.4655471181444, 340.89343043310726, 356.14796273569186, 336.4454223544576, 341.1518709861489, 335.11010080029064, 317.2323046339361, 349.09435957760195, 341.2685620095881, 337.46992368695294], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04263053881970814, "mean_inference_ms": 2.7813618685674246, "mean_action_processing_ms": 0.029185215989255827, "mean_env_wait_ms": 0.28247570108879905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "episode_reward_max": 367.3974562070364, "episode_reward_min": 221.97187502035055, "episode_reward_mean": 314.5382313711571, "episode_len_mean": 449.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [250.8790191091542, 253.17413627766385, 221.97187502035055, 257.49346368680756, 249.96627825031257, 287.78734306651415, 240.59963628194728, 285.723079967343, 270.34786137803076, 290.38431622010944, 297.3189874493223, 296.5990318099008, 290.08801719762516, 266.760625701343, 274.7172238024244, 281.159412052688, 289.7603159854647, 291.6094620108205, 304.976506410468, 299.12398142873917, 299.0405250456653, 302.4377204550649, 351.47679854760213, 297.4502038501089, 285.1912095877875, 276.3085188175078, 298.32467407349725, 278.9374628570582, 326.1309743479237, 293.77698612356005, 298.0220446999929, 296.60862107244486, 324.94112624259947, 307.6647762432989, 293.7077492416938, 293.7237774487696, 280.09488832727277, 341.3918319365821, 350.5505025135237, 291.86796398131844, 316.7885911173271, 317.51310453547296, 316.8857048198008, 329.5736585482715, 338.2544442744039, 313.01073581291064, 307.25466796098726, 325.4464209500445, 297.00010881344474, 296.4460067245177, 298.6112887117148, 313.56957924024255, 332.99931847581433, 297.22795498010544, 353.24964115069724, 307.57907123240045, 306.8763598234849, 353.86445977899155, 317.25912402209553, 321.1876698460218, 327.82495181898616, 345.71252783621026, 333.9178916003592, 327.4529539859258, 351.0471416153722, 316.8711635397632, 342.94588565713343, 334.02057662916604, 282.7421706285222, 354.45939640674715, 349.20376518844876, 326.0063625302298, 299.6010915863644, 305.35846377595976, 342.8588954532579, 352.08759492794707, 354.3759469587309, 324.6251361447712, 354.038418812101, 358.0596834391383, 341.6904903107278, 347.4227038905856, 334.2302519532311, 367.3974562070364, 341.8786603773999, 333.49825424911205, 336.79349682709005, 325.56575178034507, 364.22508533567463, 329.9446439743964, 344.4655471181444, 340.89343043310726, 356.14796273569186, 336.4454223544576, 341.1518709861489, 335.11010080029064, 317.2323046339361, 349.09435957760195, 341.2685620095881, 337.46992368695294], "episode_lengths": [449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449, 449]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.04263053881970814, "mean_inference_ms": 2.7813618685674246, "mean_action_processing_ms": 0.029185215989255827, "mean_env_wait_ms": 0.28247570108879905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "num_agent_steps_sampled": 70044, "num_agent_steps_trained": 70044, "num_env_steps_sampled": 70044, "num_env_steps_trained": 70044, "num_env_steps_sampled_this_iter": 5388, "num_env_steps_trained_this_iter": 5388, "timesteps_total": 70044, "agent_timesteps_total": 70044, "timers": {"training_iteration_time_ms": 26027.488, "load_time_ms": 0.526, "load_throughput": 10238723.248, "learn_time_ms": 9329.272, "learn_throughput": 577.537, "update_time_ms": 12.602}, "counters": {"num_env_steps_sampled": 70044, "num_env_steps_trained": 70044, "num_agent_steps_sampled": 70044, "num_agent_steps_trained": 70044}, "done": false, "episodes_total": 156, "training_iteration": 13, "trial_id": "1eff7_00000", "experiment_id": "f4c05afaa6c548bb9145335e3fe5e9fe", "date": "2022-06-26_13-13-21", "timestamp": 1656242001, "time_this_iter_s": 26.433547973632812, "time_total_s": 368.8190574645996, "pid": 9997, "hostname": "Jordans-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "TradingEnv", "observation_space": null, "action_space": null, "env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": true, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'rayExtension.callbacks.recordNetWorthCallback.RecordNetWorthCallback'>", "ignore_worker_failures": false, "recreate_failed_workers": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 5, "evaluation_duration": 1, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": true, "evaluation_config": {"env_config": {"type": "train", "window_size": 50, "min_periods": 50, "max_allowed_loss": 1, "period": 10}, "render_env": true, "explore": false}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "evaluation_num_workers": 1, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Box([[-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]\n [-inf -inf -inf -inf -inf]], [[inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]\n [inf inf inf inf inf]], (50, 5), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "lambda": 1.0}, "time_since_restore": 368.8190574645996, "timesteps_since_restore": 0, "iterations_since_restore": 13, "warmup_time": 2.82747220993042, "perf": {"cpu_util_percent": 30.344736842105267, "ram_util_percent": 81.40789473684211}}
